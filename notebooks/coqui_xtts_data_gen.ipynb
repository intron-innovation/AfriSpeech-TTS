{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2aec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install Coqui TTS\n",
    "# ! pip install -U pip\n",
    "# ! pip install TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a20799-1ea4-4228-bfd5-0b661bc7e381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/storage/talc2@talc-data2.nancy.grid5000.fr/multispeech/calcul/users/sogun/miniconda3/envs/xtts/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "\n",
    "import librosa\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fbdaf11-316f-4194-8984-be5e1c3ea6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, config_path):\n",
    "    config = XttsConfig()\n",
    "    config.load_json(config_path)\n",
    "    model = Xtts.init_from_config(config)\n",
    "    model.load_checkpoint(config, checkpoint_dir=model_path, eval=True)\n",
    "    return model, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09774209-da78-4ed3-8525-64352bd879dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410d92e9-e6c7-43e8-ae45-9fa5f7d939a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/sogun/AfriSpeech-TTS/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2044fd17-3880-48b5-9394-6d649c9cc0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(models_dict, data, dst_folder, \n",
    "                  sentences, noise_scale=0.667, \n",
    "                  noise_scale_w=0.8):\n",
    "    \n",
    "    assert len(sentences) > 1\n",
    "    for model_name in models:\n",
    "        model_path, config_path = models[model_name]\n",
    "        \n",
    "        metadata_full_path = os.path.join(dst_folder, f\"{model_name}.txt\")\n",
    "        os.makedirs(os.path.dirname(metadata_full_path), exist_ok=True)\n",
    "        \n",
    "        with open(metadata_full_path, \"w+\", encoding=\"utf-8\") as f1:\n",
    "            model, config = load_model(model_path, config_path)\n",
    "            model = model.to(device)\n",
    "            \n",
    "            for i, item in data.iterrows():\n",
    "                audio_path = Path(item.audio_paths).stem\n",
    "                \n",
    "                # stn_tst = get_text(item.transcript, hps)\n",
    "                dst_path = os.path.join(dst_folder, model_name, audio_path+\".wav\")\n",
    "                \n",
    "\n",
    "                os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "\n",
    "                sentence_idx = i%len(sentences)\n",
    "                transcript = sentences[sentence_idx]\n",
    "                \n",
    "                # transcript = tts_cleaner(transcript)\n",
    "                \n",
    "                speaker_id = int(item.user_ids_num)\n",
    "\n",
    "                if os.path.exists(dst_path): \n",
    "                    sav_path = f\"{dst_path}|{transcript}|{item.country}|{item.accent}|{str(speaker_id)}|{str(sentence_idx)}\" #.encode('ascii', 'ignore').decode('ascii')\n",
    "                    print(sav_path, file=f1)\n",
    "                    continue\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    # print(os.path.join(main_dir, \"../\" \"afrispeech_16k_trimmed\", item.audio_paths[1:]))\n",
    "                    fap = item.audio_paths[1:].replace(\"AfriSpeech-TTS-D\",  \"AfriSpeech-TTS\")\n",
    "                    speaker_wav = os.path.join(main_dir, \"../\" \"afrispeech_16k_trimmed\", fap)\n",
    "                    \n",
    "                    audio = model.synthesize(\n",
    "                        transcript,\n",
    "                        config,\n",
    "                        speaker_wav=speaker_wav,\n",
    "                        gpt_cond_len=3,\n",
    "                        language=\"en\",\n",
    "                    )[\"wav\"]\n",
    "\n",
    "                    audio = librosa.resample(audio, orig_sr=24000, target_sr=16000)\n",
    "                    \n",
    "                    write(dst_path, 16000, audio)\n",
    "                    sav_path = f\"{dst_path}|{transcript}|{item.country}|{item.accent}|{str(speaker_id)}|{str(sentence_idx)}\" #.encode('ascii', 'ignore').decode('ascii')\n",
    "                    print(sav_path, file=f1)\n",
    "                    audio = None\n",
    "                    sid = None\n",
    "                \n",
    "    print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b5f09-d0dd-4bab-b32f-9988493502e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c295de9-f3c0-4310-8937-974340340e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/srv/storage/talc2@talc-data2.nancy/multispeech/calcul/users/sogun/AfriSpeech-TTS/notebooks'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad635578-9ec9-416d-b35e-c81b9d1e1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "main_dir = os.getcwd()\n",
    "             \n",
    "test_seen = pd.read_csv(os.path.join(main_dir, \"..\", \"data/afritts-test-seen-clean.csv\"))\n",
    "\n",
    "#using general domain text with speakers in afrispeech-200 dataset\n",
    "text_data = pd.read_csv(os.path.join(main_dir, \"..\", \"data/intron-dev-public-tts-eval.csv\"))\n",
    "sentences = list(text_data.transcript_norm.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "408aa970-28e4-4cba-bb6a-f256de5185b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# # run on cpu if it fails due to memory\n",
    "models = {\n",
    "    # \"xtts\": (os.path.join(main_dir, \"../\", \"src/vits/AfriSpeech-Models/xtts\"), \n",
    "    #          os.path.join(main_dir, \"../\", \"src/vits/AfriSpeech-Models/xtts_ft/config.json\")\n",
    "    #         ),\n",
    "    \"xtts_ft\": (os.path.join(main_dir, \"../\", \"src/vits/AfriSpeech-Models/xtts_ft\"), \n",
    "             os.path.join(main_dir, \"../\", \"src/vits/AfriSpeech-Models/xtts_ft/config.json\")\n",
    "            ), # iteration 90951\n",
    "    }\n",
    "\n",
    "dst_folder = os.path.join(main_dir, \"../\", \"src/vits/afritts_test_seen\")\n",
    "\n",
    "generate_data(models, test_seen, dst_folder, sentences,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfbae2-53ba-4186-b679-8bc87eb66754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
